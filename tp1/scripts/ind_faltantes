#!/usr/bin/env python
import os, csv, random, sys
from collections import Counter
import itertools

arff_header = """
@relation dataset

@attribute GENDER { Female,Male,NA } 
@attribute AGE numeric
@attribute MEMBER_POL_PARTY { NOTAMEMBER,HDZ,HKDS,HSP,HKDZ,SDP,OTHERPARTY,AREGIONALPARTY,NA,HSLS,SSH,HSS,SDSH } 
@attribute INFO_PRESS { Yes,No,NA } 
@attribute INFO_TV_RADIO { Yes,No,NA } 
@attribute INFO_POL_MEETING { No,Yes,NA } 
@attribute INFO_PARTY_PRESS { No,Yes,NA } 
@attribute INFO_ELECT_PUBLICATION { No,Yes,NA } 
@attribute INFO_CONVERSATION { No,Yes,NA } 
@attribute INFO_NOT_INTERESTED { No,Yes,NA } 
@attribute STATE_AND_MASS_MEDIA { NOINTERVENTION,LIMITEDINFLUENCE,STRONGINFLUENCE,NA } 
@attribute RESULT_INFLUEN_VOTING { No,NA,Yes } 
@attribute WHICH_PARTY_LAST_ELECT { HDZ,KOALICIJA,INDEPENDENT,NOVOTE,SAVEZKOMUNISTA,SAVEZZELENIH,HSS,OTHERPARTY,SOCIAJALISTICKI,NA,YUGOSLAVENSKA,SRPSKA,ISTARSKI } 


@data
"""

# uso:
# ./ind_faltantes [archivo] [nro. de campo a modificar (empezando en 0)]
#
# ejemplo:
# ./ind_faltantes input/dataset.csv 2

output_dir = 'output/ej.2/'
input_data_file = sys.argv[1]
field_number = int(sys.argv[2])

def seq(start, stop, step=1):
    n = int(round((stop - start) / float(step)))
    if n > 1: return([start + step*i for i in range(n+1)])
    else: return([])
    
# sets field number [i] in record [r] to value [m]
#
def set_missing(r, i, m):
    altered_record = r[:]
    altered_record[i] = m
    return altered_record

# selects a sample of size [percentage]% of records [rr]
# and applies 'set_missing' transformation to those records
#
def transform_dataset(rr, percentage):
    number_of_records_to_alter = int((percentage / 100.0) * len(rr))
    indices_to_alter = random.sample(record_indices, number_of_records_to_alter)
    altered_records = [set_missing(r, field_number, field_mode_name) if (index in indices_to_alter or r[field_number] == 'NA') else r for (index, r) in enumerate(rr)]
    return altered_records

# selects a sample of size [percentage]% of records [rr]
# and applies 'set_missing' transformation to those records, selecting mode from [modes_per_class]
#
def transform_dataset_per_class(rr, percentage, modes_per_class):
    number_of_records_to_alter = int((percentage / 100.0) * len(rr))
    indices_to_alter = random.sample(record_indices, number_of_records_to_alter)
    altered_records = []
    for (index, r) in enumerate(rr):
        if (index in indices_to_alter) or r[field_number] == 'NA':
            mode_per_class = modes_per_class[r[class_field_number]]
            # print("record %s" % record)
            # print("changing %s to %s" % (record[field_number], mode))
            altered_records.append(set_missing(r, field_number, mode_per_class))
        else:
            altered_records.append(r)
    return altered_records

# reads input data file and calculates mode for the given field
#
with open(input_data_file, 'r') as csvfile:
    freader = csv.reader(csvfile, delimiter=',', quotechar='"')
    records = [record for record in freader]
    (field_names, records) = (records[0], records[1:])
    record_indices = range(0, len(records))

value_counter = Counter([record[field_number] for record in records])
field_mode_name, field_mode_value = value_counter.most_common(1)[0]
print("frecuencias del atributo %s (%d): %s" % (field_names[field_number], field_number, value_counter.most_common()))
print("moda del atributo %s (%d): %s, %d" % (field_names[field_number], field_number, field_mode_name, field_mode_value))

class_field_number = len(records[0]) - 1
class_values = set([record[class_field_number] for record in records])
class_frequencies = Counter([r[class_field_number] for r in records])
print(class_frequencies)
assert(sum([v for (k,v) in class_frequencies.viewitems()]) == len(records))

counters_per_class = dict()

# build counters with mode of attribute per class
sorted_records = sorted(records, key=lambda x: x[class_field_number])
groups = itertools.groupby(sorted_records, key=lambda x: x[class_field_number])
print("moda del atributo %s (%d) segun la clase:\n" % (field_names[field_number], field_number))
for (classs, group) in groups:
    field_values = [r[field_number] for r in group]
    counter = Counter(field_values)
    # print(classs, counter.most_common(), counter.most_common(1)[0][0])
    counters_per_class[classs] = counter.most_common(1)[0][0]

print(counters_per_class.viewitems())

# outputs altered datasets, one per file
#
for missing_percentage in seq(0, 85, step=2.5):
    folder, filename = os.path.split(input_data_file)
    basename, extension = os.path.splitext(filename)
    
    output_data_file = output_dir + basename + '.faltante.moda.de.atributo.' + str(field_number) + '.' + str(missing_percentage) + '.arff'
    with open(output_data_file, 'w') as f:
        f.writelines(arff_header)
        
    with open(output_data_file, 'a') as csvfile:
        fwriter = csv.writer(csvfile, delimiter=',')
        altered_records = transform_dataset(records, missing_percentage)
        fwriter.writerows(altered_records)
    print("%s: done" % output_data_file)
    
    output_data_file = output_dir + basename + '.faltante.moda.de.atributo.por.clase.' + str(field_number) + '.' + str(missing_percentage) + '.arff'
    with open(output_data_file, 'w') as f:
        f.writelines(arff_header)

    with open(output_data_file, 'a') as csvfile:
        fwriter = csv.writer(csvfile, delimiter=',')
        altered_records = transform_dataset_per_class(records, missing_percentage, counters_per_class)
        fwriter.writerows(altered_records)
    print("%s: done" % output_data_file)
